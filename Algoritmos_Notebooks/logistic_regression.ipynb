{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### REGRESSÃO LOGÍSTICA ###\n",
      "PARÂMETROS: \n",
      "\t Taxa de aprendizagem:  0.0001\n",
      "\t Número máximo de épocas:  100\n",
      "\t Total de realizações:  5 \n",
      "\n",
      "### REALIZAÇÃO  1 ###\n",
      "### FASE DE training ###\n",
      "### FASE DE TESTES ###\n",
      "Taxa de acerto:  [0.98387097] \n",
      "\n",
      "Matriz de confusão:  [[42  1]\n",
      " [ 0 19]] \n",
      "\n",
      "### REALIZAÇÃO  2 ###\n",
      "### FASE DE training ###\n",
      "### FASE DE TESTES ###\n",
      "Taxa de acerto:  [0.96774194] \n",
      "\n",
      "Matriz de confusão:  [[37  2]\n",
      " [ 0 23]] \n",
      "\n",
      "### REALIZAÇÃO  3 ###\n",
      "### FASE DE training ###\n",
      "### FASE DE TESTES ###\n",
      "Taxa de acerto:  [0.98387097] \n",
      "\n",
      "Matriz de confusão:  [[39  1]\n",
      " [ 0 22]] \n",
      "\n",
      "### REALIZAÇÃO  4 ###\n",
      "### FASE DE training ###\n",
      "### FASE DE TESTES ###\n",
      "Taxa de acerto:  [0.98387097] \n",
      "\n",
      "Matriz de confusão:  [[46  1]\n",
      " [ 0 15]] \n",
      "\n",
      "### REALIZAÇÃO  5 ###\n",
      "### FASE DE training ###\n",
      "### FASE DE TESTES ###\n",
      "Taxa de acerto:  [0.85483871] \n",
      "\n",
      "Matriz de confusão:  [[32  7]\n",
      " [ 2 21]] \n",
      "\n",
      "Acurácia:  0.9548387096774194\n",
      "Variância da Acurácia:  0.002539021852237253\n",
      "Variância do Erro:  0.030238328609481755\n",
      "Desvio Padrão da Acurácia:  0.050388707586494545\n",
      "### FIM REGRESSÃO LOGÍSTICA ###\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select the class \n",
    "def get_class(group, dataset):\n",
    "        size = len(dataset[0]) - 1\n",
    "        for i in range(len(dataset)):\n",
    "            dataset[i][size] = 1 if dataset[i][size] == group else -1\n",
    "        return dataset\n",
    "\n",
    "# Normalize\n",
    "def normalize(dataset):\n",
    "        for i in range(dataset.shape[1]-1):\n",
    "            max_ = max(dataset[:, i])\n",
    "            min_ = min(dataset[:, i])\n",
    "            for j in range(dataset.shape[0]):\n",
    "                dataset[j, i] = (dataset[j, i] - min_) / (max_ - min_)\n",
    "        return dataset\n",
    "\n",
    "# Insert the bias\n",
    "def insert_bias(data):\n",
    "    group = []\n",
    "    for i in range(len(data)):\n",
    "        group.append(np.insert(data[i], 0, -1))\n",
    "    group = np.asarray(group)\n",
    "    return group\n",
    "\n",
    "# Divide into train and test\n",
    "def divide_samples(dataset):\n",
    "    return train_test_split(dataset, test_size=0.20)\n",
    "\n",
    "# Divide into x and y \n",
    "def split_samples(dataset, n_attributes):\n",
    "    return np.array(dataset[:, 0:n_attributes-1]), np.array(dataset[:, -1])\n",
    " \n",
    " # Gradient Descendent\n",
    "def gradient_descendent(x, y, u):\n",
    "    u = np.array(u, dtype=np.float64)\n",
    "    n = (y * x)\n",
    "    d = 1 + np.exp(u)\n",
    "    return (np.array(sum(n/d), ndmin=2)).T\n",
    "\n",
    "# Return the error\n",
    "def get_error(u):\n",
    "    return np.log(1 - np.exp(-u))\n",
    "\n",
    "# Sigmoid logistic function\n",
    "def sigmoid_logistic(y):\n",
    "    y = np.array(y, dtype=np.float64)\n",
    "    return expit(-y)\n",
    "\n",
    "# Predict\n",
    "def predict(y, m):\n",
    "    y_pred = np.zeros((1, m))\n",
    "    for i in range(y.shape[0]):\n",
    "        y_pred[0][i] = 1 if y[i][0] > 0.5 else -1\n",
    "    return y_pred\n",
    "\n",
    "# Training\n",
    "def training(training_set, epochs, weights, rate):\n",
    "    epoch = 0\n",
    "    allerrors = []\n",
    "    x_train, y_train = split_samples(training_set, len(training_set[0]))\n",
    "    y_train = np.array(y_train, ndmin=2).T\n",
    "\n",
    "    for i in range(epochs):\n",
    "        u = y_train * x_train.dot(weights)\n",
    "        h = sigmoid_logistic(u)\n",
    "        y = predict(h, x_train.shape[0])\n",
    "        error = get_error(h)\n",
    "        allerrors.append(error)\n",
    "        weights = weights + gradient_descendent(x_train, y_train, u) * rate\n",
    "        epoch = i\n",
    "        \n",
    "    y = np.array(y, dtype=np.float64)\n",
    "    return weights, epoch, allerrors, get_accuracy(y.T, y_train)\n",
    "\n",
    "# Test\n",
    "def test(test_set, weights):\n",
    "    x_test, y_test = split_samples(test_set, len(test_set[0]))\n",
    "    y_test = np.array(y_test, ndmin=2).T\n",
    "    u = y_test * x_test.dot(weights)\n",
    "    h = sigmoid_logistic(u)\n",
    "    y = predict(h, x_test.shape[0])\n",
    "    y_test = np.array(y_test, ndmin=2)\n",
    "    return get_accuracy(y.T, y_test), get_confusion_matrix(y.T, y_test)\n",
    "\n",
    "# Reset the weights in each iteration\n",
    "def reset(n_attributes):\n",
    "    return np.random.rand(n_attributes-1, 1)\n",
    "\n",
    "# Return accuracy\n",
    "def get_accuracy(y_output, y_test):\n",
    "    return abs(sum(y_test == y_output)) * 1.0 / len(y_test) * 1.0\n",
    "\n",
    "# Return the confusion matrix\n",
    "def get_confusion_matrix(y_output, y_test):\n",
    "    return confusion_matrix(y_test.tolist(), y_output.tolist())\n",
    " \n",
    "# Evaluate an algorithm using hold-out   \n",
    "def execute(realizations, samples, rate, epochs):\n",
    "    print(\"### REGRESSÃO LOGÍSTICA ###\")\n",
    "    print(\"PARÂMETROS: \")\n",
    "    print(\"\\t Taxa de aprendizagem: \", rate)\n",
    "    print(\"\\t Número máximo de épocas: \", epochs)\n",
    "    print(\"\\t Total de realizações: \", realizations, \"\\n\")\n",
    "    rates = []\n",
    "    allerrors = []\n",
    "\n",
    "    for i in range(realizations):\n",
    "        weights = reset(len(samples[0]))\n",
    "        np.random.shuffle(samples)\n",
    "        training_set, test_set = divide_samples(samples)\n",
    "        print(\"### REALIZAÇÃO \", (i+1), \"###\")\n",
    "        print(\"### FASE DE training ###\")\n",
    "        weights, epoch, allerrors, accuracy = training(training_set, epochs, weights, rate)\n",
    "        print(\"### FASE DE TESTES ###\")\n",
    "        taxa, matriz = test(test_set, weights)\n",
    "        print(\"Taxa de acerto: \", taxa, \"\\n\")\n",
    "        rates.append(taxa)\n",
    "        print(\"Matriz de confusão: \", matriz, \"\\n\")\n",
    "\n",
    "    rates = np.array(rates)\n",
    "    allerrors = np.array(allerrors)\n",
    "    print(\"Acurácia: \", rates.mean())\n",
    "    print(\"Variância da Acurácia: \", rates.var())\n",
    "    print(\"Variância do Erro: \", allerrors.var())\n",
    "    print(\"Desvio Padrão da Acurácia: \", rates.std())\n",
    "    print(\"### FIM REGRESSÃO LOGÍSTICA ###\")\n",
    "\n",
    "\n",
    "dataset = np.array(pd.read_csv(\"base/column_2C.dat\", delimiter=\",\", header=None))\n",
    "dataset = get_class(\"NO\", dataset)\n",
    "dataset = normalize(dataset)\n",
    "dataset = insert_bias(dataset)\n",
    "execute(5, dataset, 1e-4, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}